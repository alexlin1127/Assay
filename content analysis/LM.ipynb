{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alex/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# 下載 NLTK 資源\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# 初始化詞形還原器\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "# 將 NLTK 的詞性標籤轉換為 WordNet 的詞性標籤\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # 預設為名詞\n",
    "\n",
    "# 改進的詞形還原函數\n",
    "def lemmatize_words(words):\n",
    "    lemmatized = set()\n",
    "    for word in words:\n",
    "        word = word.lower()  # 轉小寫\n",
    "        tagged = nltk.pos_tag([word])\n",
    "        wordnet_pos = get_wordnet_pos(tagged[0][1])  # 獲得詞的詞性\n",
    "        lemmatized.add(lemmatizer.lemmatize(word, pos=wordnet_pos))  # 進行詞形還原\n",
    "    return lemmatized\n",
    "\n",
    "def load_sentiment_words(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    positive_words = set(df.iloc[:, 1].dropna().astype(str))  # 確保為字符串\n",
    "    negative_words = set(df.iloc[:, 0].dropna().astype(str))  # 確保為字符串\n",
    "    return positive_words, negative_words\n",
    "\n",
    "def determine_sentiment(sentence, positive_words, negative_words):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    has_positive = any(word in positive_words for word in words)\n",
    "    has_negative = any(word in negative_words for word in words)\n",
    "\n",
    "    if has_negative:\n",
    "        return 'Negative'\n",
    "    elif has_positive and not has_negative:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# 載入詞庫\n",
    "positive_words, negative_words = load_sentiment_words('/Users/alex/Desktop/Assay code/content analysis/LM 字詞庫/LM字典情緒詞庫.xlsx')  # 更改為您的文件路徑\n",
    "# 還原詞庫\n",
    "positive_words = lemmatize_words(positive_words)\n",
    "negative_words = lemmatize_words(negative_words)\n",
    "\n",
    "# 測試句子\n",
    "test_sentence = \"By applying voice intelligence to all external and internal communications, Dialpad is enabling organizations to sell more effectively, conduct more efficient meetings, personalize the customer experience, and make smarter business decisions automatically, in real-time, without installing new software.\"\n",
    "sentiment = determine_sentiment(test_sentence, positive_words, negative_words)\n",
    "print(f\"{sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_excel(input_file, output_file):\n",
    "    df = pd.read_excel(input_file)\n",
    "    df['LM label'] = df['sentence'].apply(lambda x: determine_sentiment(x, positive_words, negative_words))\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "\n",
    "analyze_excel('/Users/alex/Desktop/0511assay data測試/124 sample/情緒分析變數/Total_data_v4.xlsx', '/Users/alex/Desktop/0511assay data測試/124 sample/model label result.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 2512\n",
      "Number of mismatches: 1467\n",
      "Accuracy of the model predictions: 0.42\n",
      "Precision: 0.44\n",
      "Recall: 0.47\n",
      "F1 Score: 0.38\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "file_path = '/Users/alex/Desktop/0511assay data測試/124 sample/情緒分析變數/model label result.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# 計算不匹配的次數\n",
    "mismatches = data['final label'] != data['LM label']\n",
    "mismatch_count = mismatches.sum()\n",
    "total_data = data['final label'] == data['final label']\n",
    "data_count = total_data.sum()\n",
    "\n",
    "# 計算準確率\n",
    "accuracy = accuracy_score(data['final label'], data['LM label'])\n",
    "# 計算精確率\n",
    "precision = precision_score(data['final label'], data['LM label'], average='macro')\n",
    "# 計算召回率\n",
    "recall = recall_score(data['final label'], data['LM label'], average='macro')\n",
    "# 計算 F1 分數\n",
    "f1 = f1_score(data['final label'], data['LM label'], average='macro')\n",
    "\n",
    "print(f\"Number of data: {data_count}\")\n",
    "print(f\"Number of mismatches: {mismatch_count}\")\n",
    "print(f\"Accuracy of the model predictions: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
